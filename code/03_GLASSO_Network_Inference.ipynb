{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fafc66b0",
   "metadata": {},
   "source": [
    "# Glasso Network Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38d7a302",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from sklearn.covariance import GraphicalLasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1a884e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clr_transform(data_matrix, pseudocount=10):\n",
    "    \"\"\"\n",
    "    Performs a Centered Log-Ratio (CLR) transformation.\n",
    "    Handles both Pandas DataFrames and Numpy arrays.\n",
    "    \"\"\"\n",
    "    # Convert to numpy array if it is a pandas DataFrame/Series\n",
    "    if hasattr(data_matrix, 'values'):\n",
    "        data = data_matrix.values\n",
    "    else:\n",
    "        data = data_matrix\n",
    "\n",
    "    # Add pseudocount to avoid log(0)\n",
    "    data_plus_pseudo = data + pseudocount\n",
    "    \n",
    "    # Apply logarithm\n",
    "    log_data = np.log(data_plus_pseudo)\n",
    "    \n",
    "    # Calculate the log of the geometric mean for each row (axis=1)\n",
    "    # Using .reshape(-1, 1) to allow broadcasting during subtraction\n",
    "    gmean_log = np.mean(log_data, axis=1).reshape(-1, 1)\n",
    "    \n",
    "    # CLR transform: log(x) - log(geometric_mean)\n",
    "    clr_data = log_data - gmean_log\n",
    "    \n",
    "    return clr_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe0c4358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting GLASSO Abundance Matrix Creation...\n",
      "Loading Metalog dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3473280/796080711.py:11: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df1 = pd.read_csv(file_metalog, sep=r'\\t', usecols=cols_to_use)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MGnify dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3473280/796080711.py:13: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df2 = pd.read_csv(file_mgnify, sep=r'\\t', usecols=cols_to_use)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets combined. Total rows: 9741492\n",
      "Cleaned data: 9741406 rows remaining.\n",
      "Unique GCFs identified: 73520\n",
      "GCFs passing 1% threshold: 1508\n",
      "GCFs vor Duplikat-Check: 1508\n",
      "GCFs nach Duplikat-Check: 1508\n",
      "Abundance matrix created: 61622 samples x 1508 GCFs.\n"
     ]
    }
   ],
   "source": [
    "# --- 0. FILE PATHS & CONFIGURATION ---\n",
    "file_metalog = \"../data/metalog_bgcs_with_gcf_and_tax.tsv\"\n",
    "file_mgnify = \"../data/mgnify_bgcs_with_gcf_and_tax.tsv\"\n",
    "cols_to_use = ['analysis_accession', 'gcf_id'] \n",
    "\n",
    "print(\"Starting GLASSO Abundance Matrix Creation...\")\n",
    "\n",
    "# --- 1. DATA LOADING & CONCATENATION ---\n",
    "try:\n",
    "    print(\"Loading Metalog dataset...\")\n",
    "    df1 = pd.read_csv(file_metalog, sep=r'\\t', usecols=cols_to_use)\n",
    "    print(\"Loading MGnify dataset...\")\n",
    "    df2 = pd.read_csv(file_mgnify, sep=r'\\t', usecols=cols_to_use)\n",
    "    \n",
    "    # Combine both datasets into a single dataframe\n",
    "    df = pd.concat([df1, df2], ignore_index=True)\n",
    "    print(f\"Datasets combined. Total rows: {len(df)}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"ERROR: Files not found. Please check the paths!\")\n",
    "    raise\n",
    "\n",
    "# --- 2. DATA CLEANING (Ensuring consistency across all notebooks) ---\n",
    "\n",
    "# A. Drop rows where GCF-ID is NaN\n",
    "df = df.dropna(subset=['gcf_id'])\n",
    "\n",
    "# B. Normalize GCF IDs: Convert to string and remove \".0\" suffix (fixes float conversion issues)\n",
    "df['gcf_id'] = df['gcf_id'].astype(str).str.replace(r'\\.0$', '', regex=True)\n",
    "\n",
    "# C. Filter noise: Use a comprehensive list to catch all variants of unclustered/invalid IDs\n",
    "noise_list = [\"-1\", \"nan\", \"None\", \"\", \"unknown\"]\n",
    "df = df[~df[\"gcf_id\"].isin(noise_list)]\n",
    "\n",
    "print(f\"Cleaned data: {len(df)} rows remaining.\")\n",
    "print(f\"Unique GCFs identified: {df['gcf_id'].nunique()}\")\n",
    "\n",
    "# --- 3. MEMORY-EFFICIENT PRE-FILTERING (Crucial Step) ---\n",
    "\n",
    "# A. Calculate prevalence per GCF (number of unique samples each GCF appears in)\n",
    "gcf_prevalence = df.groupby('gcf_id')['analysis_accession'].nunique()\n",
    "total_samples = df['analysis_accession'].nunique()\n",
    "\n",
    "# B. Define 1% prevalence threshold\n",
    "min_prevalence_percent = 0.01\n",
    "min_samples = int(min_prevalence_percent * total_samples)\n",
    "\n",
    "# C. Identify GCFs that pass the threshold\n",
    "passing_gcfs = gcf_prevalence[gcf_prevalence >= min_samples].index\n",
    "print(f\"GCFs passing 1% threshold: {len(passing_gcfs)}\")\n",
    "\n",
    "# D. Filter the main dataframe BEFORE pivoting to avoid RAM overflow (Performance Warning)\n",
    "df_filtered = df[df['gcf_id'].isin(passing_gcfs)]\n",
    "\n",
    "# --- 4. CREATE ABUNDANCE MATRIX (Optimized) ---\n",
    "# Group by sample and GCF to generate counts\n",
    "df_counts = df_filtered.groupby(['analysis_accession', 'gcf_id']).size()\n",
    "\n",
    "# Pivot the data (unstack) into a matrix (Samples as rows, GCFs as columns)\n",
    "df_abundanz_final = df_counts.unstack(fill_value=0)\n",
    "df_abundanz_final.index.name = 'assembly' \n",
    "print(f\"GCFs vor Duplikat-Check: {len(df_abundanz_final.columns)}\")\n",
    "\n",
    "df_transposed = df_abundanz_final.T\n",
    "df_final = df_transposed.drop_duplicates().T\n",
    "\n",
    "# Wir benennen es wieder zurück auf df_abundanz_final, \n",
    "# damit der restliche Notebook-Code (CLR etc.) einfach weiterläuft.\n",
    "df_abundanz_final = df_final \n",
    "\n",
    "print(f\"GCFs nach Duplikat-Check: {len(df_abundanz_final.columns)}\")\n",
    "print(f\"Abundance matrix created: {df_abundanz_final.shape[0]} samples x {df_abundanz_final.shape[1]} GCFs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "580ac73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying Centered Log-Ratio (CLR) transformation...\n",
      "Fitting GLASSO model with Alpha=0.002...\n",
      "GLASSO model fitted successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 5. CLR TRANSFORMATION ---\n",
    "# FIX: Pseudocount of 10 to stabilize compositions and handle zeros\n",
    "# We pass the values to ensure the output is a clean numpy matrix for GLASSO\n",
    "print(\"Applying Centered Log-Ratio (CLR) transformation...\")\n",
    "clr_data = clr_transform(df_abundanz_final, pseudocount=10)\n",
    "\n",
    "# --- 6. NETWORK INFERENCE (GLASSO) ---\n",
    "# Set alpha to 0.002 to prevent floating point errors often seen at 0.001\n",
    "new_alpha = 0.002\n",
    "print(f\"Fitting GLASSO model with Alpha={new_alpha}...\")\n",
    "\n",
    "# Initialize and fit the Graphical Lasso model\n",
    "# mode='cd' (Coordinate Descent) is generally faster for these dimensions\n",
    "model = GraphicalLasso(alpha=new_alpha, mode='cd', tol=1e-4, max_iter=1000)\n",
    "model.fit(clr_data)\n",
    "\n",
    "# The result is the precision matrix (Omega / Inverse Covariance)\n",
    "# This matrix represents direct conditional dependencies\n",
    "precision_matrix = model.precision_\n",
    "print(\"GLASSO model fitted successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8fa40aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building GLASSO Graph...\n",
      "------------------------------\n",
      "GLASSO TEST ERGEBNIS (Alpha=0.002):\n",
      "Gefundene Kooperationen (behalten): 1376\n",
      "Gefundene Konkurrenzen (gelöscht): 1288\n",
      "Finale Knoten im Graph: 1508\n",
      "Finale Kanten im Graph: 1376\n",
      "------------------------------\n",
      "Graph gespeichert als: ../data/new_data_glasso_network_FILTERED2.gexf\n"
     ]
    }
   ],
   "source": [
    "# --- 7. BUILD GLASSO GRAPH (MIT FILTER) ---\n",
    "print(\"Building GLASSO Graph...\")\n",
    "gcf_names = df_abundanz_final.columns\n",
    "G_glasso = nx.Graph()\n",
    "G_glasso.add_nodes_from(gcf_names)\n",
    "\n",
    "# Zähler für die Statistik (damit du siehst, was passiert)\n",
    "count_pos = 0\n",
    "count_neg = 0\n",
    "\n",
    "# Create graph from the precision matrix\n",
    "for i in range(len(gcf_names)):\n",
    "    for j in range(i + 1, len(gcf_names)): # Nur oberes Dreieck der Matrix\n",
    "        \n",
    "        raw_val = precision_matrix[i, j]\n",
    "        \n",
    "        if raw_val != 0:\n",
    "            # SCHRITT 1: Vorzeichen umdrehen!\n",
    "            # In der Präzisionsmatrix ist ein negativer Wert = positive Korrelation\n",
    "            association = -raw_val \n",
    "            \n",
    "            # SCHRITT 2: Filter auf NUR POSITIVE Werte\n",
    "            # Wir wollen nur Kooperationen (Communities), keine Konkurrenz\n",
    "            if association > 0:\n",
    "                count_pos += 1\n",
    "                \n",
    "                # Kante hinzufügen mit dem korrekten positiven Gewicht\n",
    "                G_glasso.add_edge(gcf_names[i], gcf_names[j], weight=association)\n",
    "            else:\n",
    "                count_neg += 1\n",
    "\n",
    "# --- 8. STATISTIK AUSGEBEN ---\n",
    "print(\"-\" * 30)\n",
    "print(f\"GLASSO TEST ERGEBNIS (Alpha={new_alpha}):\")\n",
    "print(f\"Gefundene Kooperationen (behalten): {count_pos}\")\n",
    "print(f\"Gefundene Konkurrenzen (gelöscht): {count_neg}\")\n",
    "print(f\"Finale Knoten im Graph: {G_glasso.number_of_nodes()}\")\n",
    "print(f\"Finale Kanten im Graph: {G_glasso.number_of_edges()}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# --- 9. SAVE GRAPH ---\n",
    "if G_glasso.number_of_edges() > 0:\n",
    "    # Relabel nodes to strings for .gexf\n",
    "    G_to_save = nx.relabel_nodes(G_glasso, str)\n",
    "    output_filename = \"../data/new_data_glasso_network_FILTERED2.gexf\"\n",
    "    nx.write_gexf(G_to_save, output_filename)\n",
    "    print(f\"Graph gespeichert als: {output_filename}\")\n",
    "else:\n",
    "    print(\"⚠️ ACHTUNG: Der Graph ist leer! Versuch ein niedrigeres Alpha (z.B. 0.001).\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bachelor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
